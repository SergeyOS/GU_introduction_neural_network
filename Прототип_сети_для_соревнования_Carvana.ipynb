{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Прототип сети для соревнования Carvana.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QLZzL9n9m_3",
        "colab_type": "text"
      },
      "source": [
        "## Практическое задание\n",
        "\n",
        "<ol>\n",
        "    <li>Попробуйте обучить нейронную сеть U-Net на любом другом датасете. \n",
        "        Опишите в комментарии к уроку - какой результата вы добились от нейросети? Что помогло вам улучшить ее точность?\n",
        "    </li>\n",
        "    <li>*Попробуйте свои силы в задаче Carvana на Kaggle - https://www.kaggle.com/c/carvana-image-masking-challenge/overview</li>\n",
        "    <li>*Сделайте свою реализацию U-Net на TensorFlow</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO26ut9D95pT",
        "colab_type": "text"
      },
      "source": [
        "## Подключение библиотек и настройка параметров проекта"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMTNUxpsUtoJ",
        "colab_type": "code",
        "outputId": "1576c86e-a6d4-4ad4-ae4e-b44a586dfbb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Подключение к Google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKa0vLZBUvwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = '/content/drive/My Drive/GU_neural_network/Carvana'\n",
        "BATCH_SIZE = 32\n",
        "RANDOM_STATE = 1\n",
        "SHAPE = (128, 128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t00AvKeCU-gA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqA1hYiqUigU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwTEI1Gbiufh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from skimage import io, transform\n",
        "from tensorflow.keras.preprocessing.image import array_to_img ,img_to_array ,ImageDataGenerator ,load_img\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, UpSampling2D, concatenate, Input, Flatten\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wR3e_Mbk0h3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(RANDOM_STATE)\n",
        "np.random.seed(RANDOM_STATE)\n",
        "random.seed(RANDOM_STATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nldhmlzp-GqR",
        "colab_type": "text"
      },
      "source": [
        "## Прототип Unet "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_4mziNAiykN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DownLayer(layers.Layer):\n",
        "    downconv: Conv2D = None\n",
        "    residual: Conv2D = None\n",
        "    max_pool: MaxPool2D = None\n",
        "\n",
        "    def __init__(self, filters, pool=True, **kwargs):\n",
        "        super(DownLayer, self).__init__(**kwargs)\n",
        "        self.downconv = Conv2D(filters, (3, 3), padding='same', activation='relu')\n",
        "        self.residual = Conv2D(filters, (3, 3), padding='same', activation='relu')\n",
        "        if pool:\n",
        "            self.max_pool = MaxPool2D()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.downconv(inputs)\n",
        "        x_residual = self.residual(x)\n",
        "        if self.max_pool is None:\n",
        "            return None, x_residual\n",
        "        else:\n",
        "            x_max_pool = self.max_pool(x_residual)\n",
        "            return x_max_pool, x_residual\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(DownLayer, self).get_config()\n",
        "        config.update({'conv': self.downconv.get_config()})\n",
        "        config.update({'residual': self.residual.get_config()})\n",
        "        if self.max_pool is None:\n",
        "            config.update({'max_pool': self.max_pool})\n",
        "        else:\n",
        "            config.update({'max_pool': self.max_pool.get_config()})\n",
        "        return config\n",
        "\n",
        "class UpLayer(layers.Layer):\n",
        "    upconv: Conv2D = None\n",
        "    upconv1: Conv2D = None\n",
        "    upconv2: Conv2D = None\n",
        "    upsample: UpSampling2D = None\n",
        "    concat_inputs: concatenate = None\n",
        "\n",
        "    def __init__(self, filters, **kwargs):\n",
        "        super(UpLayer, self).__init__(**kwargs)\n",
        "        filters = int(filters)\n",
        "        self.upsample = UpSampling2D()\n",
        "        self.upconv = Conv2D(filters, kernel_size=(2, 2), padding=\"same\")\n",
        "        self.upconv1 = Conv2D(filters, (3, 3), padding='same', activation='relu')\n",
        "        self.upconv2 = Conv2D(filters, (3, 3), padding='same', activation='relu')\n",
        "\n",
        "\n",
        "    def call(self, inputs, residual):\n",
        "        x = self.upsample(inputs)\n",
        "        x = self.upconv(x)\n",
        "        x = concatenate(inputs=[residual, x], axis=3)\n",
        "        x = self.upconv1(x)\n",
        "        return self.upconv2(x)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(UpLayer, self).get_config()\n",
        "        config.update({'upconv': self.upconv.get_config()})\n",
        "        config.update({'upsample': self.upsample.get_config()})\n",
        "        config.update({'upconv1': self.upconv1.get_config()})\n",
        "        config.update({'upconv2': self.upconv2.get_config()})\n",
        "        return config\n",
        "\n",
        "class UNet(Model):\n",
        "    downcascade: [] = []\n",
        "    upcascade: [] = []\n",
        "    residuals: [] = []\n",
        "    count_layers: int = 4\n",
        "    input_layer: Input = None\n",
        "    output_layer: Conv2D = None\n",
        "\n",
        "    def __init__(self, input_shape=[128, 128, 3], pool=True, **kwargs):\n",
        "        super(UNet, self).__init__()\n",
        "        filters = 64\n",
        "        #self.input_layer = Input(shape=input_shape)\n",
        "        self.output_layer = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\")\n",
        "        for i in range(self.count_layers):\n",
        "            #print(f'{i}.{filters * (2 ** i)}')\n",
        "            self.downcascade.append(DownLayer(filters=filters * (2 ** i), pool=pool))\n",
        "            self.upcascade.append(UpLayer(filters=filters * (2 ** i)))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs#self.input_layer(inputs)\n",
        "        for i in range(self.count_layers):\n",
        "            x, res = self.downcascade[i](x)\n",
        "            self.residuals.append(res)\n",
        "\n",
        "        for i in range(self.count_layers):\n",
        "            x = self.upcascade[i](inputs=x, residual=self.residuals[-i-1])\n",
        "        return self.output_layer(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VMWjHCk-MGJ",
        "colab_type": "text"
      },
      "source": [
        "Замечание: Полноценный класс реализовать не удалось. Есть ошибка в коде, но провести трасировку и найти не удалось. Model.summary() не выводит корректно слои."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gfEjkVK-j6E",
        "colab_type": "text"
      },
      "source": [
        "## Использование готовой нейронной сети"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvRB--Sp0pFH",
        "colab_type": "code",
        "outputId": "c54729f2-d818-4c68-f64b-288b2486e805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!pip install git+https://github.com/tensorflow/examples.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/tensorflow/examples.git\n",
            "  Cloning https://github.com/tensorflow/examples.git to /tmp/pip-req-build-kgpezz_7\n",
            "  Running command git clone -q https://github.com/tensorflow/examples.git /tmp/pip-req-build-kgpezz_7\n",
            "Requirement already satisfied (use --upgrade to upgrade): tensorflow-examples===ce15879e289a17da6ba6f8e36faca0a98cec56bd- from git+https://github.com/tensorflow/examples.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-examples===ce15879e289a17da6ba6f8e36faca0a98cec56bd-) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-examples===ce15879e289a17da6ba6f8e36faca0a98cec56bd-) (1.12.0)\n",
            "Building wheels for collected packages: tensorflow-examples\n",
            "  Building wheel for tensorflow-examples (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-examples: filename=tensorflow_examples-ce15879e289a17da6ba6f8e36faca0a98cec56bd_-cp36-none-any.whl size=115891 sha256=7ee5dedaea286d16a9312e0fd6bf9b4f9b8c3bcc74d82fe4ada710ad7b48f9ed\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-umywlhd1/wheels/83/64/b3/4cfa02dc6f9d16bf7257892c6a7ec602cd7e0ff6ec4d7d714d\n",
            "Successfully built tensorflow-examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZRbLDizyf3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow_examples.models.pix2pix import pix2pix\n",
        "\n",
        "def basemodel(name='basemodel', input_shape=[128, 128, 3], output_channels=1):\n",
        "  base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "\n",
        "  # Use the activations of these layers\n",
        "  layer_names = [\n",
        "      'block_1_expand_relu',   # 64x64\n",
        "      'block_3_expand_relu',   # 32x32\n",
        "      'block_6_expand_relu',   # 16x16\n",
        "      'block_13_expand_relu',  # 8x8\n",
        "      'block_16_project',      # 4x4\n",
        "  ]\n",
        "  layers = [base_model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "  # Create the feature extraction model\n",
        "  down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
        "\n",
        "  down_stack.trainable = False\n",
        "\n",
        "  up_stack = [\n",
        "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
        "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
        "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
        "    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
        "  ]\n",
        "\n",
        "  inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "  x = inputs\n",
        "\n",
        "  # Downsampling through the model\n",
        "  skips = down_stack(x)\n",
        "  x = skips[-1]\n",
        "  skips = reversed(skips[:-1])\n",
        "\n",
        "  # Upsampling and establishing the skip connections\n",
        "  for up, skip in zip(up_stack, skips):\n",
        "    x = up(x)\n",
        "    concat = tf.keras.layers.Concatenate()\n",
        "    x = concat([x, skip])\n",
        "\n",
        "  # This is the last layer of the model\n",
        "  last = tf.keras.layers.Conv2DTranspose(\n",
        "      output_channels, 3, strides=2,\n",
        "      padding='same')  #64x64 -> 128x128\n",
        "\n",
        "  x = last(x)\n",
        "\n",
        "  return tf.keras.Model(name=name, inputs=inputs, outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG9fYbUC-tYo",
        "colab_type": "text"
      },
      "source": [
        "## Генератор данных из загруженных файлов. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aWpk7xV_b9T",
        "colab_type": "text"
      },
      "source": [
        "За основу взят класс https://towardsdatascience.com/keras-data-generators-and-how-to-use-them-b69129ed779c. Использовать tensorflow-dataset.carvana не удалось (взят был из ветки гитхаба)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u46WbA7F-mr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "#base class copy from:https://towardsdatascience.com/keras-data-generators-and-how-to-use-them-b69129ed779c\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    \"\"\"Generates data for Keras\n",
        "    Sequence based data generator. Suitable for building data generator for training and prediction.\n",
        "    \"\"\"\n",
        "    def __init__(self, list_IDs, labels, image_path, mask_path,\n",
        "                 to_fit=True, batch_size=32, dim=(256, 256),\n",
        "                 n_channels=3, n_classes=10, shuffle=True):\n",
        "        \"\"\"Initialization\n",
        "        :param list_IDs: list of all 'label' ids to use in the generator\n",
        "        :param labels: list of image labels (file names)\n",
        "        :param image_path: path to images location\n",
        "        :param mask_path: path to masks location\n",
        "        :param to_fit: True to return X and y, False to return X only\n",
        "        :param batch_size: batch size at each iteration\n",
        "        :param dim: tuple indicating image dimension\n",
        "        :param n_channels: number of image channels\n",
        "        :param n_classes: number of output masks\n",
        "        :param shuffle: True to shuffle label indexes after every epoch\n",
        "        \"\"\"\n",
        "        self.list_IDs = list_IDs\n",
        "        self.labels = labels\n",
        "        self.image_path = image_path\n",
        "        self.mask_path = mask_path\n",
        "        self.to_fit = to_fit\n",
        "        self.batch_size = batch_size\n",
        "        self.dim = dim\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Denotes the number of batches per epoch\n",
        "        :return: number of batches per epoch\n",
        "        \"\"\"\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Generate one batch of data\n",
        "        :param index: index of the batch\n",
        "        :return: X and y when fitting. X only when predicting\n",
        "        \"\"\"\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X = self._generate_X(list_IDs_temp)\n",
        "\n",
        "        if self.to_fit:\n",
        "            y = self._generate_y(list_IDs_temp)\n",
        "            return X, y\n",
        "        else:\n",
        "            return X\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\n",
        "        \"\"\"\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def _generate_X(self, list_IDs_temp):\n",
        "        \"\"\"Generates data containing batch_size images\n",
        "        :param list_IDs_temp: list of label ids to load\n",
        "        :return: batch of images\n",
        "        \"\"\"\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store sample\n",
        "            X[i,] = self._load_grayscale_image(self.image_path + self.labels[ID], False)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def _generate_y(self, list_IDs_temp):\n",
        "        \"\"\"Generates data containing batch_size masks\n",
        "        :param list_IDs_temp: list of label ids to load\n",
        "        :return: batch if masks\n",
        "        \"\"\"\n",
        "        y = np.empty((self.batch_size, *self.dim), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store sample\n",
        "            y[i,] = self._load_grayscale_image(self.mask_path + self.labels[ID].split('.')[0] +'_mask.gif', True)\n",
        "\n",
        "        return y\n",
        "\n",
        "    def _load_grayscale_image(self, image_path, is_mask=True):\n",
        "        \"\"\"Load grayscale image\n",
        "        :param image_path: path to image to load\n",
        "        :return: loaded image\n",
        "        \"\"\"\n",
        "        img = io.imread(image_path, as_gray=is_mask)\n",
        "        img  = transform.resize(img, output_shape=self.dim, mode='constant')\n",
        "        img = img / 255\n",
        "        return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoH4t42N-rX6",
        "colab_type": "text"
      },
      "source": [
        "## Обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Icu4uIpY_hKp",
        "colab_type": "text"
      },
      "source": [
        "### Подготовка датасетов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_OdmXvWBi0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "all_imgs = pd.read_csv(os.path.join(PATH,'Source/train_masks.csv'))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEslatSo_CvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_path = os.path.join(PATH,'Source/train/')  \n",
        "mask_path = os.path.join(PATH,'Source/train_masks/')  \n",
        "\n",
        "train_idx ,val_idx = train_test_split(all_imgs.index ,train_size =0.8 ,test_size =0.2, random_state=RANDOM_STATE)\n",
        "\n",
        "if False:\n",
        "  train_idx = train_idx[:100]\n",
        "  val_idx = val_idx[:100]\n",
        "\n",
        "training_generator = DataGenerator(train_idx, all_imgs['img'], image_path, mask_path, batch_size=BATCH_SIZE, dim=SHAPE )\n",
        "validation_generator = DataGenerator(val_idx, all_imgs['img'], image_path, mask_path, batch_size=BATCH_SIZE, dim=SHAPE )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBliFyb3_ezq",
        "colab_type": "text"
      },
      "source": [
        "### Loss-функция"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E82jjX_Hj_PB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_loss(y_true, y_pred):\n",
        "  numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=-1)\n",
        "  denominator = tf.reduce_sum(y_true + y_pred, axis=-1)\n",
        "\n",
        "  return 1 - (numerator + 1) / (denominator + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NExOzJb_o0C",
        "colab_type": "text"
      },
      "source": [
        "### Обучение или загрузка готовой модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCqEUsH57Ae7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "USE_TRAIN_MODEL = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVFCbAH-lO0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if USE_TRAIN_MODEL:\n",
        "  # Восстановим в точности ту же модель, включая веса и оптимизатор\n",
        "  model = tf.keras.models.load_model(os.path.join(PATH,'basemodel.h5'), custom_objects={\"dice_loss\":dice_loss})\n",
        "else:\n",
        "  model = basemodel()\n",
        "model.compile(optimizer='adam',loss=dice_loss, metrics=['accuracy', dice_loss])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvIyew5T7m7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [\n",
        "  # Остановить обучение если `val_loss` перестанет улучшаться в течение 2 эпох\n",
        "  tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss')\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFOKJEG-lSBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not USE_TRAIN_MODEL:\n",
        "  history = model.fit(training_generator, epochs=3, validation_data=validation_generator, batch_size=BATCH_SIZE, verbose=1, callbacks=callbacks)\n",
        "  model.save(os.path.join(PATH,'basemodel.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMcrCpCR_wAo",
        "colab_type": "text"
      },
      "source": [
        "## Предсказание "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME9ozlmx7NaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_path = os.path.join(PATH,'Source/test/')\n",
        "all_test_imgs = os.listdir(test_path)\n",
        "test_idx = range(len(all_test_imgs))\n",
        "test_generator = DataGenerator(test_idx, all_test_imgs , test_path, mask_path=None, to_fit=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joESaca39Uhm",
        "colab_type": "code",
        "outputId": "3cc60576-36a0-40ec-9f06-4fb44fb203cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred = model.predict(test_generator, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "562/562 [==============================] - 10339s 18s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk8cQNpr_4z1",
        "colab_type": "text"
      },
      "source": [
        "Сохранение результатов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8yffRlts6Ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(os.path.join(PATH , 'test_pred.npy'), pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCXGtcwZ_80m",
        "colab_type": "text"
      },
      "source": [
        "### TODO: преобразование в rle и подготовка финального submit"
      ]
    }
  ]
}